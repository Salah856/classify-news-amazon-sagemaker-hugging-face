{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying news with HuggingFace and PyTorch on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make sure you have the updated SageMaker SDK\n",
    "!pip install \"sagemaker>=2.48.0\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the SDK session, role, region, and define the Amazon S3 bucket and prefix to be used\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this sample notebook we will use the Kaggle's News Category Dataset. You can download this dataset to your local environment and extract the JSON data.\n",
    "\n",
    "https://www.kaggle.com/rmisra/news-category-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now read our News Category Dataset, we will just keep the news headline and category columns for this sample\n",
    "df=pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "df = df.drop(['authors', 'link', 'short_description', 'date'], axis=1)\n",
    "df.columns = ['label', 'sentence'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make sure we replace any missing values with NaN, for avoiding JSON issues when reading this data\n",
    "nan_value = float(\"NaN\")\n",
    "df.replace(\"\", nan_value, inplace=True)\n",
    "df.dropna(subset = [\"sentence\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200848</th>\n",
       "      <td>TECH</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200849</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200850</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200851</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200852</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200847 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                label                                           sentence\n",
       "0               CRIME  There Were 2 Mass Shootings In Texas Last Week...\n",
       "1       ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...\n",
       "2       ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57\n",
       "3       ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
       "4       ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...\n",
       "...               ...                                                ...\n",
       "200848           TECH  RIM CEO Thorsten Heins' 'Significant' Plans Fo...\n",
       "200849         SPORTS  Maria Sharapova Stunned By Victoria Azarenka I...\n",
       "200850         SPORTS  Giants Over Patriots, Jets Over Colts Among  M...\n",
       "200851         SPORTS  Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
       "200852         SPORTS  Dwight Howard Rips Teammates After Magic Loss ...\n",
       "\n",
       "[200847 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can preview our training data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARTS' 'ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY'\n",
      " 'CRIME' 'CULTURE & ARTS' 'DIVORCE' 'EDUCATION' 'ENTERTAINMENT'\n",
      " 'ENVIRONMENT' 'FIFTY' 'FOOD & DRINK' 'GOOD NEWS' 'GREEN' 'HEALTHY LIVING'\n",
      " 'HOME & LIVING' 'IMPACT' 'LATINO VOICES' 'MEDIA' 'MONEY' 'PARENTING'\n",
      " 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION' 'SCIENCE' 'SPORTS' 'STYLE'\n",
      " 'STYLE & BEAUTY' 'TASTE' 'TECH' 'THE WORLDPOST' 'TRAVEL' 'WEDDINGS'\n",
      " 'WEIRD NEWS' 'WELLNESS' 'WOMEN' 'WORLD NEWS' 'WORLDPOST']\n"
     ]
    }
   ],
   "source": [
    "# just for keeping track of the labels' map, let's also keep a dataframe of unique and ordered labels\n",
    "labels = pd.read_csv('train-json.csv')\n",
    "map_label = pd.unique(labels.label)\n",
    "map_label = np.sort(map_label)\n",
    "print(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now split our dataset for training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df)\n",
    "train.to_csv(\"train-json.csv\", index=False)\n",
    "test.to_csv(\"test-json.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and upload the datasets to S3\n",
    "inputs_train = sagemaker_session.upload_data(\"train-json.csv\", bucket=bucket, key_prefix='{}/training-json'.format(prefix))\n",
    "inputs_test = sagemaker_session.upload_data(\"test-json.csv\", bucket=bucket, key_prefix='{}/testing-json'.format(prefix))\n",
    "print(inputs_train, inputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train (fine-tune) our model with our data, leveraging on the pre-trained models in the HuggingFace hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case #1: BERT-large (uncased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start the training of our text classifier model, this time relying on the BERT-large uncased model from the HuggingFace hub.\n",
    "\n",
    "https://huggingface.co/bert-large-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_bert = {\n",
    "\t'model_name_or_path':'bert-large-uncased',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'train_file':'/opt/ml/input/data/training/train-json.csv',\n",
    "    'validation_file':'/opt/ml/input/data/testing/test-json.csv',\n",
    "    'do_train':True,\n",
    "    'do_eval':True,\n",
    "    'num_train_epochs': 1,\n",
    "    'save_total_limit': 1\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.6.1/examples/pytorch/text-classification\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates Hugging Face estimator\n",
    "huggingface_estimator_bert = HuggingFace(\n",
    "\tentry_point='run_glue.py',\n",
    "\tsource_dir='./examples/pytorch/text-classification',\n",
    "\tinstance_type='ml.p3.16xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.6.1',\n",
    "\tpytorch_version='1.7.1',\n",
    "\tpy_version='py36',\n",
    "\thyperparameters = hyperparameters_bert,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_path='s3://{}/{}/training-json'.format(bucket, prefix)\n",
    "testing_path='s3://{}/{}/testing-json'.format(bucket, prefix)\n",
    "# starting the train job\n",
    "huggingface_estimator_bert.fit({\"training\": training_path, \"testing\": testing_path}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case #2: Amazon BORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run another training, this time using the Amazon BORT model from the HuggingFace hub.\n",
    "\n",
    "https://huggingface.co/amazon/bort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_bort = {\n",
    "\t'model_name_or_path':'amazon/bort',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'train_file':'/opt/ml/input/data/training/train-json.csv',\n",
    "    'validation_file':'/opt/ml/input/data/testing/test-json.csv',\n",
    "    'do_train':True,\n",
    "    'do_eval':True,\n",
    "    'num_train_epochs': 1,\n",
    "    'save_total_limit': 1\n",
    "    # add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.6.1/examples/pytorch/text-classification\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates Hugging Face estimator\n",
    "huggingface_estimator_bort = HuggingFace(\n",
    "\tentry_point='run_glue.py',\n",
    "\tsource_dir='./examples/pytorch/text-classification',\n",
    "\tinstance_type='ml.p3.16xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.6.1',\n",
    "\tpytorch_version='1.7.1',\n",
    "\tpy_version='py36',\n",
    "\thyperparameters = hyperparameters_bort,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_path='s3://{}/{}/training-json'.format(bucket, prefix)\n",
    "testing_path='s3://{}/{}/testing-json'.format(bucket, prefix)\n",
    "# starting the train job\n",
    "huggingface_estimator_bort.fit({\"training\": training_path, \"testing\": testing_path}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two models trained/fine-tuned to our data. We can find those model's artifacts in Amazon S3 for downloading, or host directly with an Amazon SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model_bert = HuggingFaceModel(\n",
    "    transformers_version='4.6.1',\n",
    "    pytorch_version='1.7.1',\n",
    "    py_version=\"py36\",\n",
    "    role=role,\n",
    "    model_data=huggingface_estimator_bert.model_data)\n",
    "\n",
    "huggingface_model_bort = HuggingFaceModel(\n",
    "    transformers_version='4.6.1',\n",
    "    pytorch_version='1.7.1',\n",
    "    py_version=\"py36\",\n",
    "    role=role,\n",
    "    model_data=huggingface_estimator_bort.model_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# create the predictors for deploying our Endpoints for inference\n",
    "predictor_bert = huggingface_model_bert.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=\"ml.g4dn.xlarge\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor_bort = huggingface_model_bort.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=\"ml.g4dn.xlarge\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example request, you always need to define \"inputs\"\n",
    "data = {\n",
    "   \"inputs\": \"Hollywood's biggest night was celebrated last night with the Academy Awards.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_10', 'score': 0.9710166454315186}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify with BERT model\n",
    "predictor_bert.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_10', 'score': 0.6589199304580688}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify with BORT model\n",
    "predictor_bort.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTERTAINMENT\n"
     ]
    }
   ],
   "source": [
    "# let's get the name for the returned label from our label's map\n",
    "print(map_label[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "   \"inputs\": \"Novak Djokovic's bidding for the tennis Golden Slam this year.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_28', 'score': 0.9598392844200134}]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify with BERT model\n",
    "predictor_bert.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_28', 'score': 0.5563121438026428}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify with BORT model\n",
    "predictor_bort.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPORTS\n"
     ]
    }
   ],
   "source": [
    "# let's get the name for the returned label from our label's map\n",
    "print(map_label[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
